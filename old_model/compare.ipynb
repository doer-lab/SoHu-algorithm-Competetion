{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instrument import read_bunch\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# load data from local\n",
    "train_bunch_path = './data_bunch/train_bunch.dat'\n",
    "validate_bunch_path = './data_bunch/validate_bunch.dat'\n",
    "train_bunch = read_bunch(train_bunch_path)\n",
    "validate_bunch = read_bunch(validate_bunch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建词向量空间（训练集和验证集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list = None\n",
    "max_df = 0.8\n",
    "\n",
    "# create TF-IDF words vector space with train data\n",
    "tfidf_train = Bunch(Id=train_bunch.news_id, Label=train_bunch.news_pic_label, tdm=[], vocabulary={})\n",
    "train_vectorizer = TfidfVectorizer(stop_words=stop_words_list, sublinear_tf=True, max_df=max_df)\n",
    "tfidf_train.tdm = train_vectorizer.fit_transform(train_bunch.news_words_jieba)                # jieba 分词结果或\n",
    "tfidf_train.vocabulary = train_vectorizer.vocabulary_\n",
    "\n",
    "# create TF-IDF words vector space with validate data\n",
    "tfidf_validate = Bunch(Id=validate_bunch.news_id, tdm=[], vocabulary={})\n",
    "tfidf_validate.vocabulary = tfidf_train.vocabulary\n",
    "validate_vectorizer = TfidfVectorizer(stop_words=stop_words_list, sublinear_tf=True, max_df=max_df,\n",
    "                                      vocabulary=tfidf_train.vocabulary)\n",
    "tfidf_validate.tdm = validate_vectorizer.fit_transform(validate_bunch.news_words_jieba)        # jieba 分词结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将训练数据划分为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_train.tdm,\n",
    "                                                    tfidf_train.Label,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multinomial Naive Bayes Classifier\n",
    "def classifier_naive_bayes(x_data, y_labels):\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    model = MultinomialNB(alpha=0.1453)\n",
    "    model.fit(x_data, y_labels)\n",
    "    return model\n",
    "model_naive_bayes = classifier_naive_bayes(x_train, y_train)\n",
    "print('The accuracy of classifying training data with Naive Bayes is :',\n",
    "      model_naive_bayes.score(x_test, y_test))\n",
    "print(classification_report(y_test,model_naive_bayes.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、验证集预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_naive_bayes = classifier_naive_bayes(tfidf_train.tdm,tfidf_train.Label)\n",
    "predict_naive_bayes = model_naive_bayes.predict(tfidf_validate.tdm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with KNN is : 0.6628162816281629\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.84      0.73      7192\n",
      "          1       0.44      0.07      0.13      2357\n",
      "          2       0.71      0.68      0.69      4995\n",
      "\n",
      "avg / total       0.64      0.66      0.62     14544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN Classifier\n",
    "def classifier_knn(x_data, y_labels):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    model = KNeighborsClassifier(leaf_size=40,n_neighbors=30,n_jobs=-1)\n",
    "    model.fit(x_data, y_labels)\n",
    "    return model\n",
    "\n",
    "model_knn = classifier_knn(x_train, y_train)\n",
    "print('The accuracy of classifying training data with KNN is :',\n",
    "      model_knn.score(x_test, y_test))\n",
    "print(classification_report(y_test, model_knn.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、验证集预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = classifier_knn(tfidf_train.tdm,tfidf_train.Label)\n",
    "predict_knn = model_knn.predict(tfidf_validate.tdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. store the result of predict to local, and ust it to submittion\n",
    "bayes_text = []\n",
    "for i in range(len(validate_bunch.news_id)):\n",
    "    bayes_text.append('NULL')\n",
    "\n",
    "label_predict = predict_lr\n",
    "bayes_result = []\n",
    "for i in range(len(validate_bunch.news_id)):\n",
    "    bayes_result.append(validate_bunch.news_id[i]+'\\t'+label_predict[i]+'\\t'+bayes_text[i]+'\\t'+bayes_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instrument import save_text\n",
    "\n",
    "save_path = './submittion/result_knn.txt'\n",
    "save_text(save_path, bayes_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with Logistic Regression is : 0.6747799779977998\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.69      0.72      7192\n",
      "          1       0.40      0.47      0.43      2357\n",
      "          2       0.73      0.75      0.74      4995\n",
      "\n",
      "avg / total       0.68      0.67      0.68     14544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier, speed too much time\n",
    "def classifier_logistic_regression(x_data, y_labels):\n",
    "    from sklearn.linear_model import LogisticRegressionCV\n",
    "    # lbfgs newton-cg sag\n",
    "    model = LogisticRegressionCV(Cs=5,max_iter=500,multi_class='multinomial',class_weight='balanced',n_jobs=-1)\n",
    "    model.fit(x_data, y_labels)\n",
    "    return model\n",
    "\n",
    "model_lr = classifier_logistic_regression(x_train, y_train)\n",
    "print('The accuracy of classifying training data with Logistic Regression is :',\n",
    "      model_lr.score(x_test, y_test))\n",
    "print(classification_report(y_test, model_lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证集预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = classifier_knn(tfidf_train.tdm,tfidf_train.Label)\n",
    "predict_lr = model_lr.predict(tfidf_validate.tdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. store the result of predict to local, and ust it to submittion\n",
    "bayes_text = []\n",
    "for i in range(len(validate_bunch.news_id)):\n",
    "    bayes_text.append('NULL')\n",
    "\n",
    "label_predict = predict_lr\n",
    "bayes_result = []\n",
    "for i in range(len(validate_bunch.news_id)):\n",
    "    bayes_result.append(validate_bunch.news_id[i]+'\\t'+label_predict[i]+'\\t'+bayes_text[i]+'\\t'+bayes_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instrument import save_text\n",
    "\n",
    "save_path = './submittion/result_lr.txt'\n",
    "save_text(save_path, bayes_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with Random Forest is : 0.661991199119912\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.82      0.74      7192\n",
      "          1       0.53      0.16      0.25      2357\n",
      "          2       0.67      0.68      0.67      4995\n",
      "\n",
      "avg / total       0.65      0.66      0.63     14544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "def classifier_random_forest(x_data, y_labels):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=60,max_depth=30,max_features=0.8,n_jobs=-1)\n",
    "    model.fit(x_data, y_labels)\n",
    "    return model\n",
    "\n",
    "model_random_forest = classifier_random_forest(x_train, y_train)\n",
    "print('The accuracy of classifying training data with Random Forest is :',\n",
    "      model_random_forest.score(x_test, y_test))\n",
    "print(classification_report(y_test,model_random_forest.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with Decision Tree is : 0.5731573157315731\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.67      0.66      7192\n",
      "          1       0.28      0.24      0.26      2357\n",
      "          2       0.58      0.59      0.58      4995\n",
      "\n",
      "avg / total       0.56      0.57      0.57     14544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "def classifier_decision_tree(x_data, y_labels):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(x_data, y_labels)\n",
    "    return model\n",
    "\n",
    "model_decision_tree = classifier_decision_tree(x_train, y_train)\n",
    "print('The accuracy of classifying training data with Decision Tree is :',\n",
    "      model_decision_tree.score(x_test, y_test))\n",
    "print(classification_report(y_test, model_decision_tree.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT(Gradient Boosting Decision Tree) Classifier\n",
    "def calssifier_gradient_boosting(x_data, y_labels):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    model = GradientBoostingClassifier(n_estimators=200)\n",
    "    model.fit(x_data, y_labels)\n",
    "    return model\n",
    "\n",
    "model_gbdt = calssifier_gradient_boosting(x_train, y_train)\n",
    "print('The accuracy of classifying training data with GBDT is :',\n",
    "      model_gbdt.score(x_test, y_test))\n",
    "print(classification_report(y_test,model_gbdt.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbdt = calssifier_gradient_boosting(tfidf_train.tdm,tfidf_train.Label)\n",
    "predict_gbdt = model_gbdt.predict(tfidf_validate.tdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. store the result of predict to local, and ust it to submittion\n",
    "bayes_text = []\n",
    "for i in range(len(validate_bunch.news_id)):\n",
    "    bayes_text.append('NULL')\n",
    "\n",
    "label_predict = predict_gdbt\n",
    "bayes_result = []\n",
    "for i in range(len(validate_bunch.news_id)):\n",
    "    bayes_result.append(validate_bunch.news_id[i]+'\\t'+label_predict[i]+'\\t'+bayes_text[i]+'\\t'+bayes_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instrument import save_text\n",
    "\n",
    "save_path = './submittion/result_gbdt.txt'\n",
    "save_text(save_path, bayes_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7、Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with AdaBoost is : 0.6330445544554455\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.82      0.71      7192\n",
      "          1       0.47      0.19      0.27      2357\n",
      "          2       0.67      0.57      0.62      4995\n",
      "\n",
      "avg / total       0.62      0.63      0.61     14544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "def classifier_adaboost(x_data,y_labels):\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    model = AdaBoostClassifier()\n",
    "    model.fit(x_data, y_labels)\n",
    "    return model\n",
    "\n",
    "model_adaboost = classifier_adaboost(x_train,y_train)\n",
    "print('The accuracy of classifying training data with AdaBoost is :',\n",
    "      model_adaboost.score(x_test, y_test))\n",
    "print(classification_report(y_test,model_adaboost.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adaboost = classifier_adaboost(tfidf_train.tdm,tfidf_train.Label)\n",
    "predict_adaboost = model_adaboost.predict(tfidf_validate.tdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. store the result of predict to local, and ust it to submittion\n",
    "bayes_text = []\n",
    "for i in range(len(validate_bunch.news_id)):\n",
    "    bayes_text.append('NULL')\n",
    "\n",
    "label_predict = predict_adaboost\n",
    "bayes_result = []\n",
    "for i in range(len(validate_bunch.news_id)):\n",
    "    bayes_result.append(validate_bunch.news_id[i]+'\\t'+label_predict[i]+'\\t'+bayes_text[i]+'\\t'+bayes_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instrument import save_text\n",
    "\n",
    "save_path = './submittion/result_adaboost.txt'\n",
    "save_text(save_path, bayes_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8、SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with SVM classifier 0.4944994499449945\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      1.00      0.66      7192\n",
      "          1       0.00      0.00      0.00      2357\n",
      "          2       0.00      0.00      0.00      4995\n",
      "\n",
      "avg / total       0.24      0.49      0.33     14544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# SVM(Support Vector Machine) Classifier\n",
    "def classifier_svm(x_data, y_labels):\n",
    "    from sklearn.svm import SVC\n",
    "    model = SVC(kernel='rbf', probability=True)\n",
    "    model.fit(x_data, y_labels)\n",
    "    return model\n",
    "\n",
    "model_svm = classifier_svm(x_train, y_train)\n",
    "print('The accuracy of classifying training data with SVM classifier',\n",
    "      model_svm.score(x_test, y_test))\n",
    "print(classification_report(y_test, model_svm.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9、xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with XGBoost Classifier 0.6817931793179318\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.79      0.74      7192\n",
      "          1       0.46      0.25      0.32      2357\n",
      "          2       0.71      0.73      0.72      4995\n",
      "\n",
      "avg / total       0.66      0.68      0.67     14544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# XGBoost(eXtreme Gradient Boosting) Classifier\n",
    "def classifier_xgboost(x_data, y_labels):\n",
    "    from xgboost import XGBClassifier\n",
    "    model = XGBClassifier(max_depth=8, learning_rate=0.5, min_child_weight=1,\n",
    "                          scale_pos_weight=1, n_estimators=1000, reg_lambda=4,\n",
    "                          objective='multi:softmax', num_class=3, eval_metric='merror')\n",
    "    model.fit(x_data, y_labels)\n",
    "    return model\n",
    "\n",
    "model_xgboost = classifier_xgboost(x_train, y_train)\n",
    "print('The accuracy of classifying training data with XGBoost Classifier',\n",
    "      model_xgboost.score(x_test, y_test))\n",
    "print(classification_report(y_test, model_xgboost.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgboost = calssifier_xgboost(tfidf_train.tdm,tfidf_train.Label)\n",
    "predict_xgboost = model_xgboost.predict(tfidf_validate.tdm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
