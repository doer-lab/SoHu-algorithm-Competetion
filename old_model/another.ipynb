{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入数据\n",
    "from instrument import read_bunch\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# load data from local\n",
    "train_bunch_path = './data_bunch/train_bunch.dat'\n",
    "validate_bunch_path = './data_bunch/validate_bunch.dat'\n",
    "train_bunch = read_bunch(train_bunch_path)\n",
    "validate_bunch = read_bunch(validate_bunch_path)\n",
    "\n",
    "# 创建词向量空间\n",
    "stop_words_list = None\n",
    "max_df = 0.7\n",
    "\n",
    "# create TF-IDF words vector space with train data\n",
    "tfidf_train = Bunch(Id=train_bunch.news_id, Label=train_bunch.news_pic_label, tdm=[], vocabulary={})\n",
    "train_vectorizer = TfidfVectorizer(stop_words=stop_words_list, sublinear_tf=True, max_df=max_df)\n",
    "tfidf_train.tdm = train_vectorizer.fit_transform(train_bunch.news_words_jieba)                # jieba 分词结果或\n",
    "tfidf_train.vocabulary = train_vectorizer.vocabulary_\n",
    "\n",
    "# create TF-IDF words vector space with validate data\n",
    "tfidf_validate = Bunch(Id=validate_bunch.news_id, tdm=[], vocabulary={})\n",
    "tfidf_validate.vocabulary = tfidf_train.vocabulary\n",
    "validate_vectorizer = TfidfVectorizer(stop_words=stop_words_list, sublinear_tf=True, max_df=max_df,\n",
    "                                      vocabulary=tfidf_train.vocabulary)\n",
    "tfidf_validate.tdm = validate_vectorizer.fit_transform(validate_bunch.news_words_jieba)        # jieba 分词结果\n",
    "\n",
    "# 将数据分为训练集与测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_train.tdm,\n",
    "                                                    tfidf_train.Label,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=33)\n",
    "\n",
    "# 构建模型\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  72 | elapsed: 479.8min remaining: 1439.4min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 582.3min finished\n",
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with XGBoost is : 0.692931793179318\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.82      0.75      7192\n",
      "          1       0.52      0.23      0.32      2357\n",
      "          2       0.72      0.73      0.73      4995\n",
      "\n",
      "avg / total       0.68      0.69      0.67     14544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# 寻找最佳的学习率\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgbc_1 = XGBClassifier(silent=0,                      # 设置为1则没有运行信息输出，设置为0则有运行信息输出\n",
    "                        learning_rate=0.01,            # 学习率\n",
    "                        min_child_weight=1,            # 该参数越小，越容易过拟合\n",
    "                        max_depth=8,                   # 构建的树的深度，越大越容易过拟合\n",
    "                        gamma=0,                       # 越大越保守，一般取值为0.1，0.2\n",
    "                        subsample=0.8,\n",
    "                        max_delta_step=0,              # 最大增量步长，我们允许每个树的权重估计\n",
    "                        colsample_bytree=0.8,          # 生成树时进行的列采样\n",
    "                        reg_lambda=1,                  # L2 正则化参数，越大越不容易过拟合\n",
    "                        scale_pos_weight=1,            # 取值大于0，在类别样本不平衡时有助于快速收敛\n",
    "                        objective='multi:softmax',     # 多分类问题\n",
    "                        num_class=3,                   # 类别数\n",
    "                        n_estimators=900,              # 树的个数\n",
    "                        eval_metric='merror',          # 多分类的损失函数\n",
    "                        seed=1000,\n",
    "                       n_jobs=-1\n",
    "                      )\n",
    "parameters_1 = [\n",
    "    {\n",
    "        'learning_rate': [i/100 for i in range(1,19)],\n",
    "#         'max_depth': [i for i in range(3,11)],\n",
    "#         'subsample': [i/10 for i in range(5,11)],\n",
    "#         'scale_pos_weight':[1,1.5,2,2.5],\n",
    "#         'reg_lambda': [0.5, 1, 5, 10],\n",
    "#         'n_estimators': [800, 1000, 1500, 2000],\n",
    "#         'min_child_weight': range(1, 6, 2),\n",
    "#         'gamma': [i/10.0 for i in range(0, 5)],\n",
    "#         'colsample_bytree': [i/100.0 for i in range(75, 100,5)]\n",
    "    }\n",
    "]\n",
    "gs_xgb_1 = GridSearchCV(xgbc_1, parameters_1, verbose=True, cv=4, n_jobs=-1)\n",
    "gs_xgb_1.fit(x_train,y_train)\n",
    "y_pred_1 = gs_xgb_1.predict(x_test)\n",
    "print('The accuracy of classifying training data with XGBoost is :',\n",
    "      gs_xgb_1.score(x_test, y_test))\n",
    "print(classification_report(y_test, gs_xgb_1.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=0.8, eval_metric='merror', gamma=0,\n",
       "        learning_rate=0.09, max_delta_step=0, max_depth=8,\n",
       "        min_child_weight=1, missing=None, n_estimators=900, n_jobs=1,\n",
       "        nthread=None, num_class=3, objective='multi:softprob',\n",
       "        random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "        seed=1000, silent=0, subsample=0.8),\n",
       " 0.7044436586515794,\n",
       " {'learning_rate': 0.09})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_1.best_estimator_,gs_xgb_1.best_score_,gs_xgb_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed: 181.0min remaining: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 181.2min finished\n",
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with XGBoost is : 0.692931793179318\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.82      0.75      7192\n",
      "          1       0.52      0.23      0.32      2357\n",
      "          2       0.72      0.73      0.73      4995\n",
      "\n",
      "avg / total       0.68      0.69      0.67     14544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# 寻找最佳的 subsample\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgbc_2 = XGBClassifier(silent=0,                      # 设置为1则没有运行信息输出，设置为0则有运行信息输出\n",
    "                        learning_rate=0.09,            # 学习率\n",
    "                        min_child_weight=1,            # 该参数越小，越容易过拟合\n",
    "                        max_depth=8,                   # 构建的树的深度，越大越容易过拟合\n",
    "                        gamma=0,                       # 越大越保守，一般取值为0.1，0.2\n",
    "                        subsample=0.8,\n",
    "                        max_delta_step=0,              # 最大增量步长，我们允许每个树的权重估计\n",
    "                        colsample_bytree=0.8,          # 生成树时进行的列采样\n",
    "                        reg_lambda=1,                  # L2 正则化参数，越大越不容易过拟合\n",
    "                        scale_pos_weight=1,            # 取值大于0，在类别样本不平衡时有助于快速收敛\n",
    "                        objective='multi:softmax',     # 多分类问题\n",
    "                        num_class=3,                   # 类别数\n",
    "                        n_estimators=900,              # 树的个数\n",
    "                        eval_metric='merror',          # 多分类的损失函数\n",
    "                        seed=1000,\n",
    "                      n_jobs=-1)\n",
    "parameters_2 = [\n",
    "    {\n",
    "#         'learning_rate': [i/100 for i in range(1,19)],\n",
    "#         'max_depth': [i for i in range(3,11)],\n",
    "        'subsample': [i/10 for i in range(5,11)],\n",
    "#         'scale_pos_weight':[1,1.5,2,2.5],\n",
    "#         'reg_lambda': [0.5, 1, 5, 10],\n",
    "#         'n_estimators': [800, 1000, 1500, 2000],\n",
    "#         'min_child_weight': range(1, 6, 2),\n",
    "#         'gamma': [i/10.0 for i in range(0, 5)],\n",
    "#         'colsample_bytree': [i/100.0 for i in range(75, 100,5)]\n",
    "    }\n",
    "]\n",
    "gs_xgb_2 = GridSearchCV(xgbc_2, parameters_2, verbose=True, cv=4, n_jobs=-1)\n",
    "gs_xgb_2.fit(x_train,y_train)\n",
    "y_pred_2 = gs_xgb_2.predict(x_test)\n",
    "print('The accuracy of classifying training data with XGBoost is :',\n",
    "      gs_xgb_2.score(x_test, y_test))\n",
    "print(classification_report(y_test, gs_xgb_2.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=0.8, eval_metric='merror', gamma=0,\n",
       "        learning_rate=0.09, max_delta_step=0, max_depth=8,\n",
       "        min_child_weight=1, missing=None, n_estimators=900, n_jobs=-1,\n",
       "        nthread=None, num_class=3, objective='multi:softprob',\n",
       "        random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "        seed=1000, silent=0, subsample=0.8),\n",
       " 0.7044436586515794,\n",
       " {'subsample': 0.8})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_2.best_estimator_,gs_xgb_2.best_score_,gs_xgb_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of  16 | elapsed: 131.2min remaining: 131.2min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed: 180.3min finished\n",
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with XGBoost is : 0.693069306930693\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.82      0.75      7192\n",
      "          1       0.52      0.23      0.32      2357\n",
      "          2       0.72      0.73      0.72      4995\n",
      "\n",
      "avg / total       0.68      0.69      0.67     14544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# 寻找最佳的 n_estimators\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgbc_3 = XGBClassifier(silent=0,                      # 设置为1则没有运行信息输出，设置为0则有运行信息输出\n",
    "                        learning_rate=0.09,            # 学习率\n",
    "                        min_child_weight=1,            # 该参数越小，越容易过拟合\n",
    "                        max_depth=8,                   # 构建的树的深度，越大越容易过拟合\n",
    "                        gamma=0,                       # 越大越保守，一般取值为0.1，0.2\n",
    "                        subsample=0.8,\n",
    "                        max_delta_step=0,              # 最大增量步长，我们允许每个树的权重估计\n",
    "                        colsample_bytree=0.8,          # 生成树时进行的列采样\n",
    "                        reg_lambda=1,                  # L2 正则化参数，越大越不容易过拟合\n",
    "                        scale_pos_weight=1,            # 取值大于0，在类别样本不平衡时有助于快速收敛\n",
    "                        objective='multi:softmax',     # 多分类问题\n",
    "                        num_class=3,                   # 类别数\n",
    "                        n_estimators=900,              # 树的个数\n",
    "                        eval_metric='merror',          # 多分类的损失函数\n",
    "                        seed=1000,\n",
    "                      n_jobs=-1)\n",
    "parameters_3 = [\n",
    "    {\n",
    "#         'learning_rate': [i/100 for i in range(1,19)],\n",
    "#         'max_depth': [i for i in range(3,11)],\n",
    "#         'subsample': [i/10 for i in range(5,11)],\n",
    "#         'scale_pos_weight':[1,1.5,2,2.5],\n",
    "#         'reg_lambda': [0.5, 1, 5, 10],\n",
    "        'n_estimators': [800, 1000, 1500, 2000],\n",
    "#         'min_child_weight': range(1, 6, 2),\n",
    "#         'gamma': [i/10.0 for i in range(0, 5)],\n",
    "#         'colsample_bytree': [i/100.0 for i in range(75, 100,5)]\n",
    "    }\n",
    "]\n",
    "gs_xgb_3 = GridSearchCV(xgbc_3, parameters_3, verbose=True, cv=4, n_jobs=-1)\n",
    "gs_xgb_3.fit(x_train,y_train)\n",
    "y_pred_3 = gs_xgb_3.predict(x_test)\n",
    "print('The accuracy of classifying training data with XGBoost is :',\n",
    "      gs_xgb_3.score(x_test, y_test))\n",
    "print(classification_report(y_test, gs_xgb_3.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=0.8, eval_metric='merror', gamma=0,\n",
       "        learning_rate=0.09, max_delta_step=0, max_depth=8,\n",
       "        min_child_weight=1, missing=None, n_estimators=800, n_jobs=-1,\n",
       "        nthread=None, num_class=3, objective='multi:softprob',\n",
       "        random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "        seed=1000, silent=0, subsample=0.8),\n",
       " 0.7048267326732673,\n",
       " {'n_estimators': 800})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_3.best_estimator_, gs_xgb_3.best_score_, gs_xgb_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 out of  32 | elapsed: 147.4min remaining: 88.4min\n",
      "[Parallel(n_jobs=15)]: Done  32 out of  32 | elapsed: 182.3min finished\n",
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with XGBoost is : 0.693069306930693\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.82      0.75      7192\n",
      "          1       0.52      0.23      0.32      2357\n",
      "          2       0.72      0.73      0.72      4995\n",
      "\n",
      "avg / total       0.68      0.69      0.67     14544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# 寻找最佳的 subsample\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgbc_4 = XGBClassifier(silent=0,                      # 设置为1则没有运行信息输出，设置为0则有运行信息输出\n",
    "                        learning_rate=0.09,            # 学习率\n",
    "                        min_child_weight=1,            # 该参数越小，越容易过拟合\n",
    "                        max_depth=8,                   # 构建的树的深度，越大越容易过拟合\n",
    "                        gamma=0,                       # 越大越保守，一般取值为0.1，0.2\n",
    "                        subsample=0.8,\n",
    "                        max_delta_step=0,              # 最大增量步长，我们允许每个树的权重估计\n",
    "                        colsample_bytree=0.8,          # 生成树时进行的列采样\n",
    "                        reg_lambda=1,                  # L2 正则化参数，越大越不容易过拟合\n",
    "                        scale_pos_weight=1,            # 取值大于0，在类别样本不平衡时有助于快速收敛\n",
    "                        objective='multi:softmax',     # 多分类问题\n",
    "                        num_class=3,                   # 类别数\n",
    "                        n_estimators=800,              # 树的个数\n",
    "                        eval_metric='merror',          # 多分类的损失函数\n",
    "                        seed=1000,\n",
    "                      n_jobs=-1)\n",
    "parameters_4 = [\n",
    "    {\n",
    "#         'learning_rate': [i/100 for i in range(1,19)],\n",
    "        'max_depth': [i for i in range(3,11)],\n",
    "#         'subsample': [i/10 for i in range(5,11)],\n",
    "#         'scale_pos_weight':[1,1.5,2,2.5],\n",
    "#         'reg_lambda': [0.5, 1, 5, 10],\n",
    "#         'n_estimators': [800, 1000, 1500, 2000],\n",
    "#         'min_child_weight': range(1, 6, 2),\n",
    "#         'gamma': [i/10.0 for i in range(0, 5)]\n",
    "    }\n",
    "]\n",
    "gs_xgb_4 = GridSearchCV(xgbc_4, parameters_4, verbose=2, cv=4, n_jobs=-1)\n",
    "gs_xgb_4.fit(x_train,y_train)\n",
    "y_pred_4 = gs_xgb_4.predict(x_test)\n",
    "print('The accuracy of classifying training data with XGBoost is :',\n",
    "      gs_xgb_4.score(x_test, y_test))\n",
    "print(classification_report(y_test, gs_xgb_4.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=0.8, eval_metric='merror', gamma=0,\n",
       "        learning_rate=0.09, max_delta_step=0, max_depth=8,\n",
       "        min_child_weight=1, missing=None, n_estimators=800, n_jobs=15,\n",
       "        nthread=None, num_class=3, objective='multi:softprob',\n",
       "        random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "        seed=1000, silent=0, subsample=0.8),\n",
       " 0.7048267326732673,\n",
       " {'max_depth': 8})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_4.best_estimator_, gs_xgb_4.best_score_, gs_xgb_4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  24 | elapsed: 160.1min remaining: 114.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 164.6min finished\n",
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of classifying training data with XGBoost is : 0.693069306930693\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.82      0.75      7192\n",
      "          1       0.52      0.23      0.32      2357\n",
      "          2       0.72      0.73      0.72      4995\n",
      "\n",
      "avg / total       0.68      0.69      0.67     14544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# 寻找最佳的 re_lambda\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgbc_5 = XGBClassifier(silent=0,                      # 设置为1则没有运行信息输出，设置为0则有运行信息输出\n",
    "                        learning_rate=0.09,            # 学习率\n",
    "                        min_child_weight=1,            # 该参数越小，越容易过拟合\n",
    "                        max_depth=8,                   # 构建的树的深度，越大越容易过拟合\n",
    "                        gamma=0,                       # 越大越保守，一般取值为0.1，0.2\n",
    "                        subsample=0.8,\n",
    "                        max_delta_step=0,              # 最大增量步长，我们允许每个树的权重估计\n",
    "                        colsample_bytree=0.8,          # 生成树时进行的列采样\n",
    "                        reg_lambda=1,                  # L2 正则化参数，越大越不容易过拟合\n",
    "                        scale_pos_weight=1,            # 取值大于0，在类别样本不平衡时有助于快速收敛\n",
    "                        objective='multi:softmax',     # 多分类问题\n",
    "                        num_class=3,                   # 类别数\n",
    "                        n_estimators=800,              # 树的个数\n",
    "                        eval_metric='merror',          # 多分类的损失函数\n",
    "                        seed=1000,\n",
    "                      n_jobs=-1)\n",
    "parameters_5 = {\n",
    "#         'learning_rate': [i/100 for i in range(1,19)],\n",
    "#         'max_depth': [i for i in range(3,11)],\n",
    "#         'subsample': [i/10 for i in range(5,11)],\n",
    "#         'scale_pos_weight':[1,1.5,2,2.5],\n",
    "        'reg_lambda': [0.8,1,1.2,1.5,2,5],\n",
    "#         'n_estimators': [800, 1000, 1500, 2000],\n",
    "#         'min_child_weight': range(1, 6, 2),\n",
    "#         'gamma': [i/10.0 for i in range(0, 5)]\n",
    "        }\n",
    "gs_xgb_5 = GridSearchCV(xgbc_5, parameters_5, verbose=2, cv=4, n_jobs=-1)\n",
    "gs_xgb_5.fit(x_train,y_train)\n",
    "y_pred_5 = gs_xgb_5.predict(x_test)\n",
    "print('The accuracy of classifying training data with XGBoost is :',\n",
    "      gs_xgb_5.score(x_test, y_test))\n",
    "print(classification_report(y_test, gs_xgb_5.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=0.8, eval_metric='merror', gamma=0,\n",
       "        learning_rate=0.09, max_delta_step=0, max_depth=8,\n",
       "        min_child_weight=1, missing=None, n_estimators=800, n_jobs=-1,\n",
       "        nthread=None, num_class=3, objective='multi:softprob',\n",
       "        random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "        seed=1000, silent=0, subsample=0.8),\n",
       " 0.7048267326732673,\n",
       " {'reg_lambda': 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_5.best_estimator_, gs_xgb_5.best_score_, gs_xgb_5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
